{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer, load_digits\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "# removing name column\n",
    "data = data.drop(['name'], axis=1)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.loc[:, 'pclass':], \n",
    "                                                    data['survived'], test_size=0.2, stratify=data['survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preprocessing\n",
    "NB can handle discrete features data which can be useful with categorical data.\n",
    "\n",
    "Let's see one of the advantages of NB classifier. NB is not affected by data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check if the required columns exist in x_train\n",
    "f_names = ['sex', 'embarked']\n",
    "missing_columns = [col for col in f_names if col not in x_train.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"The following columns are missing in x_train: {missing_columns}\")\n",
    "\n",
    "# One-hot-encode categorical features\n",
    "def ohe_new_features(df, features_name, encoder):\n",
    "    new_feats = encoder.transform(df[features_name])\n",
    "    # Create dataframe from encoded features with named columns\n",
    "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names_out(features_name))\n",
    "    new_df = pd.concat([df, new_cols], axis=1)\n",
    "    new_df.drop(features_name, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # Use sparse_output for newer versions\n",
    "encoder.fit(x_train[f_names])\n",
    "\n",
    "# Apply one-hot encoding to train and test data\n",
    "x_train = ohe_new_features(x_train, f_names, encoder)\n",
    "x_test = ohe_new_features(x_test, f_names, encoder)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "scaled_x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
    "scaled_x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train and test two NB models ono the data before scaling and one after scaling\n",
    "and observe if the accuracy change with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before scaling: 0.6428571428571429\n",
      "Accuracy after scaling: 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Drop rows with missing values\n",
    "x_train = x_train.dropna()\n",
    "y_train = y_train[x_train.index]  \n",
    "x_test = x_test.dropna()\n",
    "y_test = y_test[x_test.index]\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "scaled_x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
    "\n",
    "# Train and test Naive Bayes model before scaling\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "print('Accuracy before scaling:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Train and test Naive Bayes model after scaling\n",
    "nb_scaled = GaussianNB()\n",
    "nb_scaled.fit(scaled_x_train, y_train)\n",
    "y_pred_scaled = nb_scaled.predict(scaled_x_test)\n",
    "print('Accuracy after scaling:', accuracy_score(y_test, y_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regularization\n",
    "What is [Elastic-Net](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)?\n",
    "How can you specify the contribution of each part using l1 ration\n",
    "\n",
    "Apply classification on the breast cancer dataset with no regularization, l1,\n",
    "l2, and elastic-net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading Breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fitting both Lasso and Ridge\n",
    "\n",
    "Fit 3 models: Lasso and Ridge and Elastic-Net.\n",
    "Then print their accuracy and coefficients and notice the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Coefficient:\n",
      "[[ 3.78668948  0.17485914 -0.13443228 -0.02091     0.          0.\n",
      "   0.          0.          0.          0.          0.          1.42860186\n",
      "   0.         -0.08761634  0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.39676596 -0.09539229 -0.010379\n",
      "   0.          0.         -3.26223212  0.          0.          0.        ]]\n",
      "0.9824561403508771\n",
      "Ridge Coefficient:\n",
      "[[ 1.95374202  0.19252119 -0.00899708 -0.00963137 -0.13390571 -0.3946824\n",
      "  -0.59371308 -0.31538402 -0.23918092 -0.01939988  0.00280742  1.24476395\n",
      "   0.0278472  -0.08696644 -0.01512243  0.0047424  -0.04102766 -0.0382796\n",
      "  -0.03831769  0.00766508  1.02084106 -0.38642313 -0.12916799 -0.01810022\n",
      "  -0.25631168 -1.08639546 -1.46171499 -0.64946681 -0.70924229 -0.09304629]]\n",
      "0.9824561403508771\n",
      "Elastic-Net Coefficient:\n",
      "[[ 2.52270742e-03  4.65760115e-03  1.52685645e-02  1.22655983e-02\n",
      "   2.38084466e-05  2.67981242e-06 -1.53140874e-05 -6.04651712e-06\n",
      "   4.78183898e-05  1.70884377e-05  2.26934313e-05  3.58795659e-04\n",
      "   1.14877070e-04 -4.04747245e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.15998229e-06  0.00000000e+00\n",
      "   2.53333923e-03  5.93015236e-03  1.51918575e-02 -1.30615472e-02\n",
      "   3.24410800e-05  1.74297553e-06 -2.32843757e-05 -2.97472200e-06\n",
      "   6.96484933e-05  1.94871441e-05]]\n",
      "0.9181286549707602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dminnakhmetova/ML-lab/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred_lasso = lasso.predict(x_test)\n",
    "print('Lasso Coefficient:')\n",
    "print(lasso.coef_)\n",
    "print(accuracy_score(y_test, y_pred_lasso))\n",
    "\n",
    "ridge = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred_ridge = ridge.predict(x_test)\n",
    "print('Ridge Coefficient:')\n",
    "print(ridge.coef_)\n",
    "print(accuracy_score(y_test, y_pred_ridge))\n",
    "\n",
    "elasticnet = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
    "elasticnet.fit(x_train, y_train)\n",
    "y_pred_elasticnet = elasticnet.predict(x_test)\n",
    "print('Elastic-Net Coefficient:')\n",
    "print(elasticnet.coef_)\n",
    "print(accuracy_score(y_test, y_pred_elasticnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# KNN\n",
    "Compare KNN vs logistic regression\n",
    "\n",
    "---\n",
    "In ML images can be flattened to 1D vector of pixels, then we can train our\n",
    "models on them considering each pixel as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 1797 images flattened to 64-values vectors\n"
     ]
    }
   ],
   "source": [
    "# Based on https://github.com/hsu-ai-course/hsu.ai/blob/master/code/12.%20kNN%20and%20ANN%20for%20MNIST.ipynb\n",
    "digits = load_digits()\n",
    "\n",
    "print(\"Dataset shape\", digits.images.shape)\n",
    "\n",
    "# show first image\n",
    "plt.title(f\"Target: {digits.target[0]}\")\n",
    "plt.imshow(digits.images[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "print(\"Now we have {} images flattened to {}-values vectors\".format(*X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train a KNN and LR models and compare their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      0.97      0.99        35\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       0.93      0.97      0.95        29\n",
      "           4       1.00      0.97      0.98        30\n",
      "           5       0.97      0.97      0.97        40\n",
      "           6       1.00      1.00      1.00        44\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       1.00      0.95      0.97        39\n",
      "           9       0.98      1.00      0.99        41\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "LR               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.92      0.97      0.94        35\n",
      "           2       0.97      0.97      0.97        36\n",
      "           3       0.97      1.00      0.98        29\n",
      "           4       0.97      0.97      0.97        30\n",
      "           5       0.97      0.95      0.96        40\n",
      "           6       1.00      0.98      0.99        44\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.97      0.92      0.95        39\n",
      "           9       0.95      0.98      0.96        41\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, knn.predict(X_test)\n",
    "print('KNN', classification_report(y_true, y_pred))\n",
    "\n",
    "LR = LogisticRegression(max_iter=10000)\n",
    "LR.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, LR.predict(X_test)\n",
    "print('LR', classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Which model performed better? What is the advantages of each model over the other?\n",
    "\n",
    "What is the output of `classification_report` function? How to interpret it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
